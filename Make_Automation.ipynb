{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook6b6628eceb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TONNY-01/Original/blob/main/Make_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cloudinary\n",
        "import cloudinary.uploader\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "import cloudinary\n",
        "import cloudinary.uploader\n",
        "from cloudinary.utils import cloudinary_url\n",
        "from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import torch\n",
        "\n",
        "# Read input parameters\n",
        "with open('../input/stable-diffusion-input-*/input.json', 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "prompt = params['prompt']\n",
        "num_images = params['num_images']\n",
        "model_id = params['model_id']\n",
        "height = params['height']\n",
        "width = params['width']\n",
        "\n",
        "device = 'cuda'\n",
        "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16).to(device)\n",
        "pipeline.safety_checker = None\n",
        "\n",
        "compel = Compel(tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2],\n",
        "                text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],\n",
        "                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "                requires_pooled=[False, True])\n",
        "\n",
        "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
        "\n",
        "neg = \"lowres, mosaic censoring, bar censor, stripe, censored, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
        "steps = 30\n",
        "guidance = 7.5\n",
        "\n",
        "conditioning, pooled = compel([prompt, neg])\n",
        "\n",
        "images = pipeline(prompt_embeds=conditioning[0:1], pooled_prompt_embeds=pooled[0:1],\n",
        "                  negative_prompt_embeds=conditioning[1:2], negative_pooled_prompt_embeds=pooled[1:2],\n",
        "                  height=height, width=width, num_inference_steps=steps, guidance_scale=guidance,\n",
        "                  num_images_per_prompt=num_images, use_karras_sigmas=True).images\n",
        "\n",
        "# Configuration\n",
        "cloudinary.config(\n",
        "    cloud_name = \"djc6qqghd\",\n",
        "    api_key = \"272687192445414\",\n",
        "    api_secret = \"CCWiccNQ5_5U7vELMpBVtVu7RXE\",\n",
        "    secure=True\n",
        ")\n",
        "\n",
        "def upload_to_cloudinary(image_path):\n",
        "    response = cloudinary.uploader.upload(image_path)\n",
        "    return response['secure_url']\n",
        "\n",
        "for image in images:\n",
        "    # Get the current timestamp for a unique filename\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    value = images.index(image)\n",
        "\n",
        "    # Construct the save path within your Google Drive folder\n",
        "    save_path = '/kaggle/working/gens/image_{}_{}.png'.format(timestamp, value)\n",
        "\n",
        "    # Save the image\n",
        "    image.save(save_path)\n",
        "\n",
        "    print(f\"Image saved to: {save_path}\")\n",
        "\n",
        "    shareable_link = upload_to_cloudinary(save_path)\n",
        "\n",
        "    # Call Make.com webhook with the public link\n",
        "    webhook_url = 'https://hook.us1.make.com/4mkwesvlf0otqopcp9sifqqiwmxs926v'\n",
        "    requests.post(webhook_url, json={'shareable_link': shareable_link})"
      ],
      "metadata": {
        "_uuid": "20db46b0-db6e-4d78-8b0a-9aebcbb9afc4",
        "_cell_guid": "063218af-824b-43ce-8b77-f98e953e5eec",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-07-25T16:27:32.518211Z",
          "iopub.execute_input": "2024-07-25T16:27:32.518588Z",
          "iopub.status.idle": "2024-07-25T16:27:50.285537Z",
          "shell.execute_reply.started": "2024-07-25T16:27:32.518555Z",
          "shell.execute_reply": "2024-07-25T16:27:50.284118Z"
        },
        "trusted": true,
        "id": "V1--q7nfDmfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}